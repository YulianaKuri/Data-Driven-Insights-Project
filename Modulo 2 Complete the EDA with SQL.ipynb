{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"text-align:center\">\n",
    "    <a href=\"https://skills.network\" target=\"_blank\">\n",
    "    <img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/assets/logos/SN_web_lightmode.png\" width=\"200\" alt=\"Skills Network Logo\">\n",
    "    </a>\n",
    "</p>\n",
    "\n",
    "<h1 align=center><font size = 5>Hands-on Lab: Complete the EDA with SQL</font></h1>\n",
    "\n",
    "Estimated time needed: **60** minutes.\n",
    "\n",
    "## Introduction\n",
    "Using this Python notebook you will:\n",
    "\n",
    "1.  Understand the Spacex DataSet\n",
    "2.  Load the dataset  into the corresponding table in a Db2 database\n",
    "3.  Execute SQL queries to answer assignment questions \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview of the DataSet\n",
    "\n",
    "SpaceX has gained worldwide attention for a series of historic milestones. \n",
    "\n",
    "It is the only private company ever to return a spacecraft from low-earth orbit, which it first accomplished in December 2010.\n",
    "SpaceX advertises Falcon 9 rocket launches on its website with a cost of 62 million dollars wheras other providers cost upward of 165 million dollars each, much of the savings is because Space X can reuse the first stage. \n",
    "\n",
    "\n",
    "Therefore if we can determine if the first stage will land, we can determine the cost of a launch. \n",
    "\n",
    "This information can be used if an alternate company wants to bid against SpaceX for a rocket launch.\n",
    "\n",
    "This dataset includes a record for each payload carried during a SpaceX mission into outer space.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download the datasets\n",
    "\n",
    "This assignment requires you to load the spacex dataset.\n",
    "\n",
    "In many cases the dataset to be analyzed is available as a .CSV (comma separated values) file, perhaps on the internet. Click on the link below to download and save the dataset (.CSV file):\n",
    "\n",
    " <a href=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-DS0321EN-SkillsNetwork/labs/module_2/data/Spacex.csv\" target=\"_blank\">Spacex DataSet</a>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sqlalchemy==1.4\n",
      "  Downloading SQLAlchemy-1.4.0.tar.gz (7.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.4/7.4 MB\u001b[0m \u001b[31m135.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "  Preparing metadata (setup.py) ... \u001b[?2done\n",
      "\u001b[?25hRequirement already satisfied: greenlet!=0.4.17 in /opt/conda/lib/python3.12/site-packages (from sqlalchemy==1.4) (3.1.1)\n",
      "Building wheels for collected packages: sqlalchemy\n",
      "  Building wheel for sqlalchemy (setup.py) ..done\n",
      "\u001b[?25h  Created wheel for sqlalchemy: filename=SQLAlchemy-1.4.0-cp312-cp312-linux_x86_64.whl size=1447176 sha256=6fd46faacc8c968f400b50473bca057fd0ad1687e4773e7890d50e1a2323644c\n",
      "  Stored in directory: /home/jupyterlab/.cache/pip/wheels/a6/b1/f8/f3401c8d8cde72a608b1399e8e0277aa542a70efd4defe44a5\n",
      "Successfully built sqlalchemy\n",
      "Installing collected packages: sqlalchemy\n",
      "  Attempting uninstall: sqlalchemy\n",
      "    Found existing installation: SQLAlchemy 2.0.37\n",
      "    Uninstalling SQLAlchemy-2.0.37:\n",
      "      Successfully uninstalled SQLAlchemy-2.0.37\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "jupyterhub 5.2.1 requires SQLAlchemy>=1.4.1, but you have sqlalchemy 1.4.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed sqlalchemy-1.4.0\n",
      "Collecting ipython-sql\n",
      "  Downloading ipython_sql-0.5.0-py3-none-any.whl.metadata (17 kB)\n",
      "Collecting prettytable (from ipython-sql)\n",
      "  Downloading prettytable-3.16.0-py3-none-any.whl.metadata (33 kB)\n",
      "Requirement already satisfied: ipython in /opt/conda/lib/python3.12/site-packages (from ipython-sql) (8.31.0)\n",
      "Collecting sqlalchemy>=2.0 (from ipython-sql)\n",
      "  Downloading sqlalchemy-2.0.40-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.6 kB)\n",
      "Collecting sqlparse (from ipython-sql)\n",
      "  Downloading sqlparse-0.5.3-py3-none-any.whl.metadata (3.9 kB)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.12/site-packages (from ipython-sql) (1.17.0)\n",
      "Requirement already satisfied: ipython-genutils in /opt/conda/lib/python3.12/site-packages (from ipython-sql) (0.2.0)\n",
      "Requirement already satisfied: greenlet>=1 in /opt/conda/lib/python3.12/site-packages (from sqlalchemy>=2.0->ipython-sql) (3.1.1)\n",
      "Requirement already satisfied: typing-extensions>=4.6.0 in /opt/conda/lib/python3.12/site-packages (from sqlalchemy>=2.0->ipython-sql) (4.12.2)\n",
      "Requirement already satisfied: decorator in /opt/conda/lib/python3.12/site-packages (from ipython->ipython-sql) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in /opt/conda/lib/python3.12/site-packages (from ipython->ipython-sql) (0.19.2)\n",
      "Requirement already satisfied: matplotlib-inline in /opt/conda/lib/python3.12/site-packages (from ipython->ipython-sql) (0.1.7)\n",
      "Requirement already satisfied: pexpect>4.3 in /opt/conda/lib/python3.12/site-packages (from ipython->ipython-sql) (4.9.0)\n",
      "Requirement already satisfied: prompt_toolkit<3.1.0,>=3.0.41 in /opt/conda/lib/python3.12/site-packages (from ipython->ipython-sql) (3.0.50)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /opt/conda/lib/python3.12/site-packages (from ipython->ipython-sql) (2.19.1)\n",
      "Requirement already satisfied: stack_data in /opt/conda/lib/python3.12/site-packages (from ipython->ipython-sql) (0.6.3)\n",
      "Requirement already satisfied: traitlets>=5.13.0 in /opt/conda/lib/python3.12/site-packages (from ipython->ipython-sql) (5.14.3)\n",
      "Requirement already satisfied: wcwidth in /opt/conda/lib/python3.12/site-packages (from prettytable->ipython-sql) (0.2.13)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /opt/conda/lib/python3.12/site-packages (from jedi>=0.16->ipython->ipython-sql) (0.8.4)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /opt/conda/lib/python3.12/site-packages (from pexpect>4.3->ipython->ipython-sql) (0.7.0)\n",
      "Requirement already satisfied: executing>=1.2.0 in /opt/conda/lib/python3.12/site-packages (from stack_data->ipython->ipython-sql) (2.1.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /opt/conda/lib/python3.12/site-packages (from stack_data->ipython->ipython-sql) (3.0.0)\n",
      "Requirement already satisfied: pure_eval in /opt/conda/lib/python3.12/site-packages (from stack_data->ipython->ipython-sql) (0.2.3)\n",
      "Downloading ipython_sql-0.5.0-py3-none-any.whl (20 kB)\n",
      "Downloading sqlalchemy-2.0.40-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m137.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading prettytable-3.16.0-py3-none-any.whl (33 kB)\n",
      "Downloading sqlparse-0.5.3-py3-none-any.whl (44 kB)\n",
      "Installing collected packages: sqlparse, sqlalchemy, prettytable, ipython-sql\n",
      "  Attempting uninstall: sqlalchemy\n",
      "    Found existing installation: SQLAlchemy 1.4.0\n",
      "    Uninstalling SQLAlchemy-1.4.0:\n",
      "      Successfully uninstalled SQLAlchemy-1.4.0\n",
      "Successfully installed ipython-sql-0.5.0 prettytable-3.16.0 sqlalchemy-2.0.40 sqlparse-0.5.3\n",
      "Collecting pandas\n",
      "  Downloading pandas-2.2.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (89 kB)\n",
      "Collecting numpy>=1.26.0 (from pandas)\n",
      "  Downloading numpy-2.2.5-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (62 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.12/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.12/site-packages (from pandas) (2024.2)\n",
      "Collecting tzdata>=2022.7 (from pandas)\n",
      "  Downloading tzdata-2025.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Downloading pandas-2.2.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.7/12.7 MB\u001b[0m \u001b[31m171.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading numpy-2.2.5-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.1/16.1 MB\u001b[0m \u001b[31m196.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "Downloading tzdata-2025.2-py2.py3-none-any.whl (347 kB)\n",
      "Installing collected packages: tzdata, numpy, pandas\n",
      "Successfully installed numpy-2.2.5 pandas-2.2.3 tzdata-2025.2\n"
     ]
    }
   ],
   "source": [
    "!pip install sqlalchemy==1.4\n",
    "!pip install ipython-sql\n",
    "!pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sqlalchemy==1.4.47\n",
      "  Downloading SQLAlchemy-1.4.47.tar.gz (8.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.6/8.6 MB\u001b[0m \u001b[31m157.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "  Preparing metadata (setup.py) ... \u001b[?2done\n",
      "\u001b[?25hCollecting greenlet!=0.4.17 (from sqlalchemy==1.4.47)\n",
      "  Downloading greenlet-3.2.2-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (4.1 kB)\n",
      "Downloading greenlet-3.2.2-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (603 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m603.9/603.9 kB\u001b[0m \u001b[31m49.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hBuilding wheels for collected packages: sqlalchemy\n",
      "  Building wheel for sqlalchemy (setup.py) ..done\n",
      "\u001b[?25h  Created wheel for sqlalchemy: filename=SQLAlchemy-1.4.47-cp312-cp312-linux_x86_64.whl size=1568073 sha256=eec3bc3a776539b2e45d794067ef3f9724cd70ea7a9c60fbe9bd13559a67dc69\n",
      "  Stored in directory: /home/jupyterlab/.cache/pip/wheels/03/c7/09/4e868814a13d1e9a6fca219ba3b9bf30b0c064e5c7841497b2\n",
      "Successfully built sqlalchemy\n",
      "Installing collected packages: greenlet, sqlalchemy\n",
      "  Attempting uninstall: greenlet\n",
      "    Found existing installation: greenlet 3.1.1\n",
      "    Uninstalling greenlet-3.1.1:\n",
      "      Successfully uninstalled greenlet-3.1.1\n",
      "  Attempting uninstall: sqlalchemy\n",
      "    Found existing installation: SQLAlchemy 2.0.40\n",
      "    Uninstalling SQLAlchemy-2.0.40:\n",
      "      Successfully uninstalled SQLAlchemy-2.0.40\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "ipython-sql 0.5.0 requires sqlalchemy>=2.0, but you have sqlalchemy 1.4.47 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed greenlet-3.2.2 sqlalchemy-1.4.47\n",
      "Requirement already satisfied: ipython-sql in /opt/conda/lib/python3.12/site-packages (0.5.0)\n",
      "Requirement already satisfied: prettytable in /opt/conda/lib/python3.12/site-packages (from ipython-sql) (3.16.0)\n",
      "Requirement already satisfied: ipython in /opt/conda/lib/python3.12/site-packages (from ipython-sql) (8.31.0)\n",
      "Collecting sqlalchemy>=2.0 (from ipython-sql)\n",
      "  Using cached sqlalchemy-2.0.40-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.6 kB)\n",
      "Requirement already satisfied: sqlparse in /opt/conda/lib/python3.12/site-packages (from ipython-sql) (0.5.3)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.12/site-packages (from ipython-sql) (1.17.0)\n",
      "Requirement already satisfied: ipython-genutils in /opt/conda/lib/python3.12/site-packages (from ipython-sql) (0.2.0)\n",
      "Requirement already satisfied: greenlet>=1 in /opt/conda/lib/python3.12/site-packages (from sqlalchemy>=2.0->ipython-sql) (3.2.2)\n",
      "Requirement already satisfied: typing-extensions>=4.6.0 in /opt/conda/lib/python3.12/site-packages (from sqlalchemy>=2.0->ipython-sql) (4.12.2)\n",
      "Requirement already satisfied: decorator in /opt/conda/lib/python3.12/site-packages (from ipython->ipython-sql) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in /opt/conda/lib/python3.12/site-packages (from ipython->ipython-sql) (0.19.2)\n",
      "Requirement already satisfied: matplotlib-inline in /opt/conda/lib/python3.12/site-packages (from ipython->ipython-sql) (0.1.7)\n",
      "Requirement already satisfied: pexpect>4.3 in /opt/conda/lib/python3.12/site-packages (from ipython->ipython-sql) (4.9.0)\n",
      "Requirement already satisfied: prompt_toolkit<3.1.0,>=3.0.41 in /opt/conda/lib/python3.12/site-packages (from ipython->ipython-sql) (3.0.50)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /opt/conda/lib/python3.12/site-packages (from ipython->ipython-sql) (2.19.1)\n",
      "Requirement already satisfied: stack_data in /opt/conda/lib/python3.12/site-packages (from ipython->ipython-sql) (0.6.3)\n",
      "Requirement already satisfied: traitlets>=5.13.0 in /opt/conda/lib/python3.12/site-packages (from ipython->ipython-sql) (5.14.3)\n",
      "Requirement already satisfied: wcwidth in /opt/conda/lib/python3.12/site-packages (from prettytable->ipython-sql) (0.2.13)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /opt/conda/lib/python3.12/site-packages (from jedi>=0.16->ipython->ipython-sql) (0.8.4)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /opt/conda/lib/python3.12/site-packages (from pexpect>4.3->ipython->ipython-sql) (0.7.0)\n",
      "Requirement already satisfied: executing>=1.2.0 in /opt/conda/lib/python3.12/site-packages (from stack_data->ipython->ipython-sql) (2.1.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /opt/conda/lib/python3.12/site-packages (from stack_data->ipython->ipython-sql) (3.0.0)\n",
      "Requirement already satisfied: pure_eval in /opt/conda/lib/python3.12/site-packages (from stack_data->ipython->ipython-sql) (0.2.3)\n",
      "Using cached sqlalchemy-2.0.40-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)\n",
      "Installing collected packages: sqlalchemy\n",
      "  Attempting uninstall: sqlalchemy\n",
      "    Found existing installation: SQLAlchemy 1.4.47\n",
      "    Uninstalling SQLAlchemy-1.4.47:\n",
      "      Successfully uninstalled SQLAlchemy-1.4.47\n",
      "Successfully installed sqlalchemy-2.0.40\n"
     ]
    }
   ],
   "source": [
    "!pip install sqlalchemy==1.4.47 --force-reinstall\n",
    "!pip install ipython-sql\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connect to the database\n",
    "\n",
    "Let us first load the SQL extension and establish a connection with the database\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext sql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv, sqlite3\n",
    "\n",
    "con = sqlite3.connect(\"my_data1.db\")\n",
    "cur = con.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "%sql sqlite:///my_data1.db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "101"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-DS0321EN-SkillsNetwork/labs/module_2/data/Spacex.csv\")\n",
    "df.to_sql(\"SPACEXTBL\", con, if_exists='replace', index=False,method=\"multi\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:This below code is added to remove blank rows from table**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * sqlite:///my_data1.db\n",
      "(sqlite3.OperationalError) table SPACEXTABLE already exists\n",
      "[SQL: create table SPACEXTABLE as select * from SPACEXTBL where Date is not null]\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n"
     ]
    }
   ],
   "source": [
    "%sql create table SPACEXTABLE as select * from SPACEXTBL where Date is not null"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tasks\n",
    "\n",
    "Now write and execute SQL queries to solve the assignment tasks.\n",
    "\n",
    "**Note: If the column names are in mixed case enclose it in double quotes\n",
    "   For Example \"Landing_Outcome\"** . \n",
    "\n",
    "   \n",
    "\n",
    "### Task 1\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "##### Display the names of the unique launch sites  in the space mission\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique Launch Sites:\n",
      "    Launch_Site\n",
      "0   CCAFS LC-40\n",
      "1   VAFB SLC-4E\n",
      "2    KSC LC-39A\n",
      "3  CCAFS SLC-40\n"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "\n",
    "# Connect to the SQLite database\n",
    "conn = sqlite3.connect(\"my_data1.db\")\n",
    "\n",
    "# Execute the SQL query\n",
    "query = 'SELECT DISTINCT \"Launch_Site\" FROM SPACEXTABLE'\n",
    "df_result = pd.read_sql_query(query, conn)\n",
    "\n",
    "# Display the result\n",
    "print(\"Unique Launch Sites:\")\n",
    "print(df_result)\n",
    "\n",
    "# Close the connection\n",
    "conn.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Task 2\n",
    "\n",
    "\n",
    "#####  Display 5 records where launch sites begin with the string 'KSC' \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Records where Launch_Site begins with 'KSC':\n",
      "         Date Time (UTC) Booster_Version Launch_Site        Payload  \\\n",
      "0  2017-02-19   14:39:00   F9 FT B1031.1  KSC LC-39A  SpaceX CRS-10   \n",
      "1  2017-03-16    6:00:00     F9 FT B1030  KSC LC-39A    EchoStar 23   \n",
      "2  2017-03-30   22:27:00  F9 FT  B1021.2  KSC LC-39A         SES-10   \n",
      "3  2017-05-01   11:15:00   F9 FT B1032.1  KSC LC-39A        NROL-76   \n",
      "4  2017-05-15   23:21:00     F9 FT B1034  KSC LC-39A  Inmarsat-5 F4   \n",
      "\n",
      "   PAYLOAD_MASS__KG_      Orbit    Customer Mission_Outcome  \\\n",
      "0               2490  LEO (ISS)  NASA (CRS)         Success   \n",
      "1               5600        GTO    EchoStar         Success   \n",
      "2               5300        GTO         SES         Success   \n",
      "3               5300        LEO         NRO         Success   \n",
      "4               6070        GTO    Inmarsat         Success   \n",
      "\n",
      "        Landing_Outcome  \n",
      "0  Success (ground pad)  \n",
      "1            No attempt  \n",
      "2  Success (drone ship)  \n",
      "3  Success (ground pad)  \n",
      "4            No attempt  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Connect to the SQLite database\n",
    "conn = sqlite3.connect(\"my_data1.db\")\n",
    "\n",
    "# Execute the SQL query to get 5 records where Launch_Site begins with 'KSC'\n",
    "query = '''\n",
    "SELECT * \n",
    "FROM SPACEXTABLE \n",
    "WHERE \"Launch_Site\" LIKE 'KSC%' \n",
    "LIMIT 5\n",
    "'''\n",
    "df_result = pd.read_sql_query(query, conn)\n",
    "\n",
    "# Display the result\n",
    "print(\"Records where Launch_Site begins with 'KSC':\")\n",
    "print(df_result)\n",
    "\n",
    "# Close the connection\n",
    "conn.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "##### Display the total payload mass carried by boosters launched by NASA (CRS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Payload Mass Carried by NASA (CRS):\n",
      "   Total_Payload_Mass\n",
      "0               45596\n"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "\n",
    "# Connect to the SQLite database\n",
    "conn = sqlite3.connect(\"my_data1.db\")\n",
    "\n",
    "# SQL query to get the total payload mass for NASA (CRS) launches\n",
    "query = '''\n",
    "SELECT SUM(\"PAYLOAD_MASS__KG_\") AS Total_Payload_Mass\n",
    "FROM SPACEXTABLE\n",
    "WHERE Customer = 'NASA (CRS)'\n",
    "'''\n",
    "\n",
    "# Run the query and load the result into a DataFrame\n",
    "df_result = pd.read_sql_query(query, conn)\n",
    "\n",
    "# Display the result\n",
    "print(\"Total Payload Mass Carried by NASA (CRS):\")\n",
    "print(df_result)\n",
    "\n",
    "# Close the connection\n",
    "conn.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 4\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "##### Display average payload mass carried by booster version F9 v1.1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Payload Mass for Booster Version F9 v1.1:\n",
      "   Average_Payload_Mass\n",
      "0                2928.4\n"
     ]
    }
   ],
   "source": [
    "# Connect to the SQLite database\n",
    "conn = sqlite3.connect(\"my_data1.db\")\n",
    "\n",
    "# SQL query to calculate the average payload mass for booster version F9 v1.1\n",
    "query = '''\n",
    "SELECT AVG(\"PAYLOAD_MASS__KG_\") AS Average_Payload_Mass\n",
    "FROM SPACEXTABLE\n",
    "WHERE \"Booster_Version\" = 'F9 v1.1'\n",
    "'''\n",
    "\n",
    "# Run the query and load the result into a DataFrame\n",
    "df_result = pd.read_sql_query(query, conn)\n",
    "\n",
    "# Display the result\n",
    "print(\"Average Payload Mass for Booster Version F9 v1.1:\")\n",
    "print(df_result)\n",
    "\n",
    "# Close the connection\n",
    "conn.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 5\n",
    "\n",
    "##### List the date where the succesful landing outcome in drone ship was acheived.\n",
    "\n",
    "\n",
    "_Hint:Use min function_ \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First successful drone ship landing date:\n",
      "  First_Successful_Drone_Landing\n",
      "0                     2016-04-08\n"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "\n",
    "# Connect to the SQLite database\n",
    "conn = sqlite3.connect(\"my_data1.db\")\n",
    "\n",
    "# SQL query to find the earliest date of successful landing on a drone ship\n",
    "query = '''\n",
    "SELECT MIN(Date) AS First_Successful_Drone_Landing\n",
    "FROM SPACEXTABLE\n",
    "WHERE \"Landing_Outcome\" = 'Success (drone ship)'\n",
    "'''\n",
    "\n",
    "# Run the query and load the result into a DataFrame\n",
    "df_result = pd.read_sql_query(query, conn)\n",
    "\n",
    "# Display the result\n",
    "print(\"First successful drone ship landing date:\")\n",
    "print(df_result)\n",
    "\n",
    "# Close the connection\n",
    "conn.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 6\n",
    "\n",
    "##### List the names of the boosters which have success in ground pad  and have payload mass greater than 4000 but less than 6000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Booster versions with successful ground pad landing and payload between 4000 and 6000 kg:\n",
      "  Booster_Version\n",
      "0   F9 FT B1032.1\n",
      "1   F9 B4 B1040.1\n",
      "2   F9 B4 B1043.1\n"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "\n",
    "# Connect to the SQLite database\n",
    "conn = sqlite3.connect(\"my_data1.db\")\n",
    "\n",
    "# SQL query to find booster names with successful ground pad landing and payload between 4000 and 6000 kg\n",
    "query = '''\n",
    "SELECT DISTINCT \"Booster_Version\"\n",
    "FROM SPACEXTABLE\n",
    "WHERE \"Landing_Outcome\" = 'Success (ground pad)'\n",
    "AND \"PAYLOAD_MASS__KG_\" > 4000\n",
    "AND \"PAYLOAD_MASS__KG_\" < 6000\n",
    "'''\n",
    "\n",
    "# Run the query and load the result into a DataFrame\n",
    "df_result = pd.read_sql_query(query, conn)\n",
    "\n",
    "# Display the result\n",
    "print(\"Booster versions with successful ground pad landing and payload between 4000 and 6000 kg:\")\n",
    "print(df_result)\n",
    "\n",
    "# Close the connection\n",
    "conn.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 7\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "##### List the total number of successful and failure mission outcomes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of mission outcomes (success and failure):\n",
      "                    Mission_Outcome  Outcome_Count\n",
      "0               Failure (in flight)              1\n",
      "1                           Success             98\n",
      "2                          Success               1\n",
      "3  Success (payload status unclear)              1\n"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "\n",
    "# Connect to the SQLite database\n",
    "conn = sqlite3.connect(\"my_data1.db\")\n",
    "\n",
    "# SQL query to count each type of mission outcome (success and failure)\n",
    "query = '''\n",
    "SELECT \"Mission_Outcome\", COUNT(*) AS Outcome_Count\n",
    "FROM SPACEXTABLE\n",
    "GROUP BY \"Mission_Outcome\"\n",
    "'''\n",
    "\n",
    "# Run the query and load the result into a DataFrame\n",
    "df_result = pd.read_sql_query(query, conn)\n",
    "\n",
    "# Display the result\n",
    "print(\"Total number of mission outcomes (success and failure):\")\n",
    "print(df_result)\n",
    "\n",
    "# Close the connection\n",
    "conn.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 8\n",
    "\n",
    "\n",
    "\n",
    "##### List all the booster_versions that have carried the maximum payload mass. Use a subquery.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Booster versions that carried the maximum payload mass:\n",
      "   Booster_Version\n",
      "0    F9 B5 B1048.4\n",
      "1    F9 B5 B1049.4\n",
      "2    F9 B5 B1051.3\n",
      "3    F9 B5 B1056.4\n",
      "4    F9 B5 B1048.5\n",
      "5    F9 B5 B1051.4\n",
      "6    F9 B5 B1049.5\n",
      "7   F9 B5 B1060.2 \n",
      "8   F9 B5 B1058.3 \n",
      "9    F9 B5 B1051.6\n",
      "10   F9 B5 B1060.3\n",
      "11  F9 B5 B1049.7 \n"
     ]
    }
   ],
   "source": [
    "\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "\n",
    "# Connect to the SQLite database\n",
    "conn = sqlite3.connect(\"my_data1.db\")\n",
    "\n",
    "# SQL query using a subquery to find booster versions with the maximum payload mass\n",
    "query = '''\n",
    "SELECT DISTINCT \"Booster_Version\"\n",
    "FROM SPACEXTABLE\n",
    "WHERE \"PAYLOAD_MASS__KG_\" = (\n",
    "    SELECT MAX(\"PAYLOAD_MASS__KG_\")\n",
    "    FROM SPACEXTABLE\n",
    ")\n",
    "'''\n",
    "\n",
    "# Run the query and load the result into a DataFrame\n",
    "df_result = pd.read_sql_query(query, conn)\n",
    "\n",
    "# Display the result\n",
    "print(\"Booster versions that carried the maximum payload mass:\")\n",
    "print(df_result)\n",
    "\n",
    "# Close the connection\n",
    "conn.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 9\n",
    "\n",
    "\n",
    "##### List the records which will display the month names, succesful landing_outcomes in ground pad ,booster versions, launch_site for the months in year 2017\n",
    "**Note: SQLLite does not support monthnames. So you need to use substr(Date,6,2) for month, substr(Date,9,2) for date, substr(Date,0,5),='2017' for year.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Records for 2017 with successful ground pad landings:\n",
      "  Month       Landing_Outcome Booster_Version   Launch_Site\n",
      "0    02  Success (ground pad)   F9 FT B1031.1    KSC LC-39A\n",
      "1    05  Success (ground pad)   F9 FT B1032.1    KSC LC-39A\n",
      "2    06  Success (ground pad)   F9 FT B1035.1    KSC LC-39A\n",
      "3    08  Success (ground pad)   F9 B4 B1039.1    KSC LC-39A\n",
      "4    09  Success (ground pad)   F9 B4 B1040.1    KSC LC-39A\n",
      "5    12  Success (ground pad)  F9 FT  B1035.2  CCAFS SLC-40\n"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "\n",
    "# Connect to the SQLite database\n",
    "conn = sqlite3.connect(\"my_data1.db\")\n",
    "\n",
    "# SQL query using substr() to filter for year 2017 and extract month number\n",
    "query = '''\n",
    "SELECT \n",
    "    substr(Date, 6, 2) AS Month,\n",
    "    \"Landing_Outcome\",\n",
    "    \"Booster_Version\",\n",
    "    \"Launch_Site\"\n",
    "FROM SPACEXTABLE\n",
    "WHERE substr(Date, 1, 4) = '2017'\n",
    "  AND \"Landing_Outcome\" = 'Success (ground pad)'\n",
    "'''\n",
    "\n",
    "# Execute query\n",
    "df_result = pd.read_sql_query(query, conn)\n",
    "\n",
    "# Display the result\n",
    "print(\"Records for 2017 with successful ground pad landings:\")\n",
    "print(df_result)\n",
    "\n",
    "# Close the connection\n",
    "conn.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 10\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "##### Rank the count of landing outcomes (such as Failure (drone ship) or Success (ground pad)) between the date 2010-06-04 and 2017-03-20, in descending order\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Landing outcomes ranked by count between 2010-06-04 and 2017-03-20:\n",
      "          Landing_Outcome  Outcome_Count\n",
      "0              No attempt             10\n",
      "1    Success (drone ship)              5\n",
      "2    Failure (drone ship)              5\n",
      "3    Success (ground pad)              3\n",
      "4      Controlled (ocean)              3\n",
      "5    Uncontrolled (ocean)              2\n",
      "6     Failure (parachute)              2\n",
      "7  Precluded (drone ship)              1\n"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "\n",
    "# Connect to the SQLite database\n",
    "conn = sqlite3.connect(\"my_data1.db\")\n",
    "\n",
    "# SQL query to count and rank landing outcomes between two dates\n",
    "query = '''\n",
    "SELECT \"Landing_Outcome\", COUNT(*) AS Outcome_Count\n",
    "FROM SPACEXTABLE\n",
    "WHERE Date BETWEEN '2010-06-04' AND '2017-03-20'\n",
    "GROUP BY \"Landing_Outcome\"\n",
    "ORDER BY Outcome_Count DESC\n",
    "'''\n",
    "\n",
    "# Execute query\n",
    "df_result = pd.read_sql_query(query, conn)\n",
    "\n",
    "# Display the result\n",
    "print(\"Landing outcomes ranked by count between 2010-06-04 and 2017-03-20:\")\n",
    "print(df_result)\n",
    "\n",
    "# Close the connection\n",
    "conn.close()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['FlightNumber',\n",
       " 'PayloadMass',\n",
       " 'Orbit',\n",
       " 'LaunchSite',\n",
       " 'Flights',\n",
       " 'GridFins',\n",
       " 'Reused',\n",
       " 'Legs',\n",
       " 'LandingPad',\n",
       " 'Block',\n",
       " 'ReusedCount',\n",
       " 'Serial']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "['FlightNumber', 'PayloadMass', 'Orbit', 'LaunchSite', 'Flights',\n",
    " 'GridFins', 'Reused', 'Legs', 'LandingPad', 'Block',\n",
    " 'ReusedCount', 'Serial']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Date', 'Time (UTC)', 'Booster_Version', 'Launch_Site', 'Payload',\n",
      "       'PAYLOAD_MASS__KG_', 'Orbit', 'Customer', 'Mission_Outcome',\n",
      "       'Landing_Outcome'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = df[['Date', 'Time (UTC)', 'Booster_Version', 'Launch_Site', 'Payload',\n",
    "       'PAYLOAD_MASS__KG_', 'Orbit', 'Customer', 'Mission_Outcome',\n",
    "       'Landing_Outcome']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Date', 'Time (UTC)', 'Booster_Version', 'Launch_Site', 'Payload',\n",
      "       'PAYLOAD_MASS__KG_', 'Orbit', 'Customer', 'Mission_Outcome',\n",
      "       'Landing_Outcome'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(features.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of columns after one-hot encoding: 20\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Let's say your original features DataFrame is called `features`\n",
    "# and it includes the columns you listed\n",
    "categorical_cols = ['Orbit', 'Launch_Site']\n",
    "\n",
    "# Apply one-hot encoding\n",
    "features_one_hot = pd.get_dummies(features, columns=categorical_cols)\n",
    "\n",
    "# Count total number of columns after encoding\n",
    "print(\"Total number of columns after one-hot encoding:\", features_one_hot.shape[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reference Links\n",
    "\n",
    "* <a href =\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-DB0201EN-SkillsNetwork/labs/Module%203/LAB-String_Patterns_Sorting_Grouping.md.html\">Hands-on Lab : String Patterns, Sorting and Grouping</a>  \n",
    "\n",
    "*  <a  href=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-DB0201EN-SkillsNetwork/labs/Labs_Coursera_V5/labs/Lab%20-%20Built-in%20functions%20/Hands-on_Lab__Built-in_Functions.md.html\">Hands-on Lab: Built-in functions</a>\n",
    "\n",
    "*  <a  href=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-DB0201EN-SkillsNetwork/labs/Labs_Coursera_V5/labs/Lab%20-%20Sub-queries%20and%20Nested%20SELECTs%20/instructional-labs.md.html\">Hands-on Lab : Sub-queries and Nested SELECT Statements</a>\n",
    "\n",
    "*   <a href=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-DB0201EN-SkillsNetwork/labs/Module%205/DB0201EN-Week3-1-3-SQLmagic.ipynb\">Hands-on Tutorial: Accessing Databases with SQL magic</a>\n",
    "\n",
    "*  <a href= \"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-DB0201EN-SkillsNetwork/labs/Module%205/DB0201EN-Week3-1-4-Analyzing.ipynb\">Hands-on Lab: Analyzing a real World Data Set</a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Author(s)\n",
    "\n",
    "<h4> Lakshmi Holla </h4>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other Contributors\n",
    "\n",
    "<h4> Rav Ahuja </h4>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--## Change log\n",
    "| Date | Version | Changed by | Change Description |\n",
    "|------|--------|--------|---------|\n",
    "| 2021-07-09 | 0.2 |Lakshmi Holla | Changes made in magic sql|\n",
    "| 2021-05-20 | 0.1 |Lakshmi Holla | Created Initial Version |\n",
    "--!>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <h3 align=\"center\"> © IBM Corporation 2021. All rights reserved. <h3/>\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  },
  "prev_pub_hash": "f4e9d52e6f1d349bc812fc948cc3020934b9f83d28cd068dd22a39062f97e6c0"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
